{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a080a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester 5\\Information Retrieval\\Information-Retrieval\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea4efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan stopwords NLTK sudah diunduh\n",
    "try:\n",
    "    stopwords.words('indonesian')\n",
    "except LookupError:\n",
    "    print(\"Mengunduh stopwords untuk Bahasa Indonesia...\")\n",
    "    nltk.download('stopwords')\n",
    "    print(\"Selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d29e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path index & data\n",
    "INDEX_DIR = \"my_index\"\n",
    "JSON_FILE = \"json-file/docs.jsonl\"  # ganti sesuai nama file\n",
    "\n",
    "# Load searcher\n",
    "searcher = LuceneSearcher(INDEX_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdea2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('indonesian'))\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    \"\"\"Fungsi untuk melakukan stemming pada list token.\"\"\"\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Fungsi lengkap untuk preprocessing: lowercase, tokenisasi, stopword removal, stemming.\"\"\"\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    # 2. Tokenisasi + Hapus Stopwords\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    # 3. Stemming\n",
    "    stemmed_tokens = stem_tokens(tokens)\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f74d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(path):\n",
    "    docs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        first_char = f.read(1)\n",
    "        f.seek(0)\n",
    "        if first_char == \"[\":  # format array JSON\n",
    "            docs = json.load(f)\n",
    "        else:  # format NDJSON\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        docs.append(json.loads(line))\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Gagal parse baris: {line[:50]}... ({e})\")\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f6bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TECH_QUERIES = [\n",
    "    \"gemini ai\",\n",
    "    \"laptop gaming\",\n",
    "    \"hack\",\n",
    "    \"teknologi\",\n",
    "    \"komputer\",\n",
    "    \"mobile legends\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f58589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ground_truth():\n",
    "    docs = load_docs(JSON_FILE)\n",
    "    ground_truth = {}\n",
    "\n",
    "    print(\"Membangun Ground Truth\")\n",
    "    for query in TECH_QUERIES:\n",
    "        relevant_docs = []\n",
    "        \n",
    "        # 1. Ubah query menjadi daftar kata-kata kunci (lowercased)\n",
    "        query_words = query.lower().split()\n",
    "\n",
    "        for doc in docs:\n",
    "            doc_id = str(doc.get(\"id\"))\n",
    "            doc_text = (doc.get(\"title\", \"\") + \" \" + doc.get(\"content\", \"\")).lower()\n",
    "\n",
    "            # 2. LOGIKA UTAMA: Cek jika SEMUA kata kunci dari query ada di dalam teks dokumen\n",
    "            # all() akan mengembalikan True hanya jika semua kondisi di dalamnya True\n",
    "            if all(word in doc_text for word in query_words):\n",
    "                relevant_docs.append(doc_id)\n",
    "        \n",
    "        if relevant_docs:\n",
    "            ground_truth[query] = relevant_docs\n",
    "            print(f\"Query '{query}' menemukan {len(relevant_docs)} dokumen relevan.\")\n",
    "        else:\n",
    "            print(f\"Query '{query}' tidak menemukan dokumen relevan.\")\n",
    "            \n",
    "    print(\"-\" * 30)\n",
    "    return ground_truth, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe16d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membangun Ground Truth\n",
      "Query 'gemini ai' menemukan 25 dokumen relevan.\n",
      "Query 'laptop gaming' menemukan 3 dokumen relevan.\n",
      "Query 'hack' menemukan 3 dokumen relevan.\n",
      "Query 'teknologi' menemukan 5 dokumen relevan.\n",
      "Query 'komputer' menemukan 3 dokumen relevan.\n",
      "Query 'mobile legends' menemukan 4 dokumen relevan.\n",
      "------------------------------\n",
      "=== Hasil Evaluasi IR (Format Laporan) ===\n",
      "Metode: BM25 Title+Content\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Relevan (Top-10)</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini ai</td>\n",
       "      <td>8/10 (dok. #170, #277, #496, #316, #168, #25, ...</td>\n",
       "      <td>8/10 = 0.80</td>\n",
       "      <td>8/25 = 0.32</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laptop gaming</td>\n",
       "      <td>3/10 (dok. #78, #352, #687)</td>\n",
       "      <td>3/10 = 0.30</td>\n",
       "      <td>3/3 = 1.00</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hack</td>\n",
       "      <td>2/4 (dok. #99, #454)</td>\n",
       "      <td>2/4 = 0.50</td>\n",
       "      <td>2/3 = 0.67</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teknologi</td>\n",
       "      <td>2/10 (dok. #332, #85)</td>\n",
       "      <td>2/10 = 0.20</td>\n",
       "      <td>2/5 = 0.40</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komputer</td>\n",
       "      <td>2/10 (dok. #437, #284)</td>\n",
       "      <td>2/10 = 0.20</td>\n",
       "      <td>2/3 = 0.67</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobile legends</td>\n",
       "      <td>4/10 (dok. #29, #487, #450, #162)</td>\n",
       "      <td>4/10 = 0.40</td>\n",
       "      <td>4/4 = 1.00</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Query                                   Relevan (Top-10)  \\\n",
       "0       gemini ai  8/10 (dok. #170, #277, #496, #316, #168, #25, ...   \n",
       "1   laptop gaming                        3/10 (dok. #78, #352, #687)   \n",
       "2            hack                               2/4 (dok. #99, #454)   \n",
       "3       teknologi                              2/10 (dok. #332, #85)   \n",
       "4        komputer                             2/10 (dok. #437, #284)   \n",
       "5  mobile legends                  4/10 (dok. #29, #487, #450, #162)   \n",
       "\n",
       "     Precision       Recall F1-Score  \n",
       "0  8/10 = 0.80  8/25 = 0.32     0.46  \n",
       "1  3/10 = 0.30   3/3 = 1.00     0.46  \n",
       "2   2/4 = 0.50   2/3 = 0.67     0.57  \n",
       "3  2/10 = 0.20   2/5 = 0.40     0.27  \n",
       "4  2/10 = 0.20   2/3 = 0.67     0.31  \n",
       "5  4/10 = 0.40   4/4 = 1.00     0.57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rata-rata Evaluasi === (dari semua query)\n",
      "Precision : 0.40\n",
      "Recall    : 0.68\n",
      "F1-score  : 0.44\n"
     ]
    }
   ],
   "source": [
    "# [Sel ke-8, file: evaluate.ipynb]\n",
    "# GANTIKAN SEL LAMA ANDA DENGAN YANG INI\n",
    "\n",
    "def evaluate_ir(k=10):\n",
    "    ground_truth, documents = build_ground_truth()\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    print(\"=== Hasil Evaluasi IR (Format Laporan) ===\")\n",
    "    print(\"Metode: BM25 Title+Content\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # DataFrame untuk menampung hasil\n",
    "    results_data = []\n",
    "\n",
    "    for query, relevant_docs in ground_truth.items():\n",
    "        processed_query = preprocess_text(query)\n",
    "        hits = searcher.search(processed_query, k=k)\n",
    "        retrieved = [h.docid for h in hits]\n",
    "\n",
    "        retrieved_relevant = [d for d in retrieved if d in relevant_docs]\n",
    "\n",
    "        # --- Perhitungan Metrik (Sama seperti sebelumnya) ---\n",
    "        retrieved_count = len(retrieved)\n",
    "        retrieved_relevant_count = len(retrieved_relevant)\n",
    "        total_relevant_count = len(relevant_docs)\n",
    "\n",
    "        precision = retrieved_relevant_count / retrieved_count if retrieved_count else 0\n",
    "        recall = retrieved_relevant_count / total_relevant_count if total_relevant_count else 0\n",
    "        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "        # --- BAGIAN PRINT YANG DIMODIFIKASI ---\n",
    "        \n",
    "        # 1. Buat string daftar dokumen yang relevan (e.g., \"#170, #277, ...\")\n",
    "        doc_id_str = \", \".join([f\"#{docid}\" for docid in retrieved_relevant])\n",
    "        if not doc_id_str:\n",
    "            doc_id_str = \"Tidak ada\"\n",
    "\n",
    "        # 2. Simpan data untuk tabel\n",
    "        results_data.append({\n",
    "            \"Query\": query,\n",
    "            \"Relevan (Top-10)\": f\"{retrieved_relevant_count}/{retrieved_count} (dok. {doc_id_str})\",\n",
    "            \"Precision\": f\"{retrieved_relevant_count}/{retrieved_count} = {precision:.2f}\",\n",
    "            \"Recall\": f\"{retrieved_relevant_count}/{total_relevant_count} = {recall:.2f}\",\n",
    "            \"F1-Score\": f\"{f1:.2f}\"  # <-- TAMBAHAN BARU\n",
    "        })\n",
    "        \n",
    "\n",
    "    # --- Tampilkan Hasil dalam Bentuk Tabel (Menggunakan Pandas) ---\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        # Atur urutan kolom agar F1-Score ada di akhir\n",
    "        df_results = pd.DataFrame(results_data, columns=[\"Query\", \"Relevan (Top-10)\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "        display(df_results)\n",
    "    except ImportError:\n",
    "        print(\"Install pandas (pip install pandas) untuk melihat tabel.\")\n",
    "\n",
    "\n",
    "    print(\"\\n=== Rata-rata Evaluasi === (dari semua query)\")\n",
    "    if all_precisions:\n",
    "        print(f\"Precision : {sum(all_precisions)/len(all_precisions):.2f}\")\n",
    "        print(f\"Recall    : {sum(all_recalls)/len(all_recalls):.2f}\")\n",
    "        print(f\"F1-score  : {sum(all_f1s)/len(all_f1s):.2f}\")\n",
    "    else:\n",
    "        print(\"Tidak ada hasil evaluasi (cek ground truth atau query).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Pastikan pandas sudah ter-install jika Anda menjalankan ini di Jupyter\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except ImportError:\n",
    "        print(\"Peringatan: 'pip install pandas' agar hasil evaluasi bisa tampil sebagai tabel.\")\n",
    "        \n",
    "    evaluate_ir(k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
